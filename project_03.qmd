---
title: "Social Factors and Children's Mental Health"
subtitle: "A cross-sectional study in the Midwest"
author: "Walaa Alshaia and Sarah Albalawi"
date: last-modified
format: 
  html:
    toc: true
    number-sections: true
    code-fold: show
    code-tools: true
    code-overflow: wrap
    embed-resources: true
    date-format: iso
    theme: spacelab 
---

## R Packages and Setup {.unnumbered}

```{r}
#| message: false
#| warning: false

knitr::opts_chunk$set(comment = NA) 

library(janitor) 
library(broom)
library(gt)
library(gtsummary)
library(Hmisc)
library(ggrepel)
library(GGally)
library(knitr)
library(mosaic)
library(naniar)
library(patchwork)
library(simputation)
library(rms)
library(caret)
library(pROC)
library(sessioninfo)
library(tidyverse) 

opts_chunk$set(comment=NA)
options(dplyr.summarise.inform = FALSE)

theme_set(theme_bw()) 
```

# Data Source

The data set used for this study is the National Health Interview Survey (NHIS). The NHIS is part of the Centers for Disease Control and Prevention (CDC) and the main source of statistics on the health of the civilian non-institutionalized population of the United States. The data is collected through interviews conducted at the households of the subjects. The target population are non-institutionalized US citizens, including group homes and shelters. The NHIS aims to obtain a representative sample of the US population through geographically clustered sampling techniques. The data collection is conducted throughout the year, from January to December. For this study, the 2022 NHIS sample child interview data set was used. The file can be found at <https://www.cdc.gov/nchs/nhis/2022nhis.htm>.

# The Subjects

The subjects of this study are children (any individual below the age of 18) living in civilian non-institutionalized households. The sample is restricted to those in the Midwest region of the U.S.

# Loading and Tidying the Data

## Loading the Raw Data

For this study, we will use the 2022 NHIS sample child interview data set. The file can be found at <https://www.cdc.gov/nchs/nhis/2022nhis.htm>.

```{r}


R.child22 <- read_csv("child22.csv",
                      guess_max = 4000,
                      show_col_types = FALSE) |>
    mutate(across(where(is.character), as_factor))
                      

dim (R.child22)

```

## Cleaning the Data

In this step, we will mutate, rename, and regroup our variables as needed.

### Selecting Variables of Interest

Given the extensive size of the raw data set, we will filter the data set to include the variables of interest for our analysis. Additionally, we will narrow the population of interest to those living in the Midwest.

```{r}

child_raw <- R.child22 |>
  select (HHX,REGION, SEX_C, AGEP_C, MAXEDUCP_C, PHSTAT_C, SDQTOT_C, VIOLENEV_C, HISPALLP_C) |> 
  filter(`REGION` == 2, AGEP_C < 97, SEX_C < 10, MAXEDUCP_C < 97 , PHSTAT_C < 10, SDQTOT_C < 90, VIOLENEV_C < 10, HISPALLP_C < 8)

child_raw

```

We will mutate the variables with levels containing non-relevant values, such as "refused to answer" or "not ascertained", into `NA`.

```{r}

child_raw$SEX_C= na_if(child_raw$SEX_C, 7)
child_raw$SEX_C= na_if(child_raw$SEX_C, 8)
child_raw$SEX_C= na_if(child_raw$SEX_C, 9)
child_raw$SDQTOT_C= na_if(child_raw$SDQTOT_C,88)
child_raw$PHSTAT_C = na_if(child_raw$PHSTAT_C, 7)
child_raw$PHSTAT_C = na_if(child_raw$PHSTAT_C, 8)
child_raw$PHSTAT_C = na_if(child_raw$PHSTAT_C, 9)
child_raw$VIOLENEV_C = na_if(child_raw$VIOLENEV_C, 7)
child_raw$VIOLENEV_C = na_if(child_raw$VIOLENEV_C, 8)
child_raw$VIOLENEV_C = na_if(child_raw$VIOLENEV_C, 9)

child_raw

```

### Converting Variable Types

We will convert the variables into factors, except for `HHX`, which will remain as a character. The variables `AGE_C` and `SDQTOT_C` are the only quantitative variables and will be converted into numeric variables.

```{r}

child_raw <- child_raw |>
  mutate_if(is.vector, as.factor)|>
  mutate(HHX = as.character(HHX))|>
  mutate(AGEP_C = as.numeric(AGEP_C))|>
  mutate(SDQTOT_C= as.numeric(SDQTOT_C))

child_raw

```

### Changing Variable Names

We will assign meaningful names to the variables of our study.

```{r}
child22 <- child_raw|>
  select(HHX, SEX_C, AGEP_C, MAXEDUCP_C, PHSTAT_C, SDQTOT_C, VIOLENEV_C, HISPALLP_C)

child22 <- child22 |>
  rename(sex = SEX_C,
         age = AGEP_C,
         race = HISPALLP_C,
         adult_edu = MAXEDUCP_C,
         health_status = PHSTAT_C, 
         sdq = SDQTOT_C, 
         violence = VIOLENEV_C,
         id = HHX)

child22
```

### Working with Categorical Predictors

For this project, we have four categorical variables acting as predictors for both analyses and one binary outcome for the logistic regression analysis: `sex`, `race`, `adult_edu`, `health_status`, and `violence`

#### sex variable

We will rename the numeric levels of `sex` into meaningful labels:

```{r}

child22 <- child22|>
mutate(sex = fct_recode (sex, 
                                  "Male"= "1", 
                                  "Female"= "2"))
tabyl(child22$sex)

```

#### race variable

We will rename each category of the `race` variable to clarify the meaning of each level. We will also combine the levels with the lowest frequencies under *other* category.

```{r}

child22 <- child22 |>
  mutate(
    race = fct_recode(race,
      "Hispanic" = "1",
      "White" = "2",
      "African_American" = "3",
      "Asian" = "4",
      "other" = "5",
      "other" = "6",
      "other" = "7" ))

tabyl(child22$race)

```

#### adult_edu variable

We will start by renaming the `adult_edu` numeric levels into meaningful words:

```{r}
#| warning: false

child22 <- child22 |>
mutate(adult_edu= fct_recode (adult_edu, 
                                  "Grade 1-11"= "1", 
                                  "12th grade,no diploma"= "2", 
                                  "GED"="3", 
                                  "High School Graduate"= "4", 
                                  "Some college, no degree"= "5", 
                                  "Associate degree-nonacademic-"="6",
                                  "Associate degree-academic-"="7",
                                  "Bachelor's degree"="8",
                                  "Master's degree"="9",
                                  "Professional School"="10"))
tabyl(child22$adult_edu)

```

We will collapse the present levels to the following:

-   Incomplete high school
-   Complete high school
-   Incomplete college
-   Associate's Degree
-   Bachelor's Degree
-   Graduate Degree

```{r}

child22 <- child22 |>
mutate (adult_edu= fct_collapse(adult_edu, incomplete_highschool = c("Grade 1-11", "12th grade,no diploma"),
                                complete_highschool = c("GED", "High School Graduate"),
                                incomplete_college = c("Some college, no degree"),
                                      associate_degree = c("Associate degree-nonacademic-", "Associate degree-academic-"),
                                      bachelors_degree = c("Bachelor's degree"),
                                      graduate_degree = c("Master's degree", "Professional School")))
tabyl(child22$adult_edu)

```

#### health_status variable

We will start by renaming the `health_status` numeric levels into meaningful labels:

```{r}

child22 <- child22|>
mutate(health_status= fct_recode (health_status, 
                                  "Excellent"= "1", 
                                  "Very Good"= "2", 
                                  "Good"="3", 
                                  "Fair"= "4", 
                                  "Poor"= "5"))
tabyl(child22$health_status)

```

We would like to collapse them into the following categories:

-   Excellent
-   Very Good
-   Not very good

```{r}
#| warning: false

child22 <- child22 |>
mutate (health_status= fct_collapse(health_status, "Not very good" = c("Good","Fair", "Poor")))
tabyl(child22$health_status)

```

#### violence variable

We will rename the `violence` numeric levels into meaningful labels:

```{r}

child22 <- child22|>
mutate(violence = fct_recode (violence, 
                                  "Yes"= "1", 
                                  "No"= "2"))
tabyl(child22$violence)

```

### Assessment of Missing Values

We will employ the `miss_var_summary` function to assess missing values in the study variables. The two outcomes of the linear and logistic regression (`sdq` and `violence`) have missing values. One of the predictors (`health_status`) also has a missing value.

```{r}
miss_var_summary(child22)
```

### Arranging the Tibble

This is the count of the final data set `child22` after refining the variables of interest:

```{r}

dim(child22)

```

we have 1191 observations and 8 variables of interest (including `id`).

# The Tidy Tibble

## Listing the Tibble

We will observe the finalized version of our data set after cleaning and filtering the variables:

```{r}

child22

```

## Size and Identifiers

The tibble frame `child22` consists of 1191 rows (*observations*) and 8 columns (*variables*). The `id` functions as our indicator variable, guaranteeing that each row in our data set has a distinct identification. This is demonstrated in the code provided below.

```{r}

identical(nrow(child22), n_distinct(child22$id))

```

## Save The Tibble

We will use the write_rds function to store the finalized data set.

```{r}

write_rds(child22,"child22.Rds")

```

# The Code Book

## Defining the Variables

| Variable | Role | Type | Description |
|:---|:---|:---|:---|
| **id** | Subject Identifier Number | \- | Subject character code |
| **sex** | input | Binary | Male and Female |
| **age** | input | Quantitative | Child age in years |
| **race** | input | 5 Categories | Multiple race groups (White, Hispanic, African American, Asian, Other) |
| **adult_edu** | input | 6 Categories | Level of education of the adults in the child's family (Incomplete high school, Complete high school, Incomplete college, Associate degree, Bachelors degree, Graduate degree ) |
| **health_status** | input | 3 Categories | The health status of the children interviewed (Excellent, Very Good, Not very good) |
| **sdq** | **Outcome** | Quantitative | Strengths and Difficulties Questionnaire (SDQ) total score |
| **violence** | **Outcome** | Binary | The subject is a Victim of/ have witnessed violence (yes or no) |

```{r}

tbl_summary(select(child22, -id),
        label = list(
            sex = "Sex",
            age = "Age in years",
            race = "Race category",
            adult_health = "Adult Educational level",
            Health_Status = "Child Health Status",
            sdq = "Strengths and Difficulties Questionnaire (SDQ) total score",
            violence = "Victim of or witnessed violence"),
        stat = list( all_continuous() ~ 
                "{median} [{min} to {max}]" ))
```

## Numerical Description

```{r}
#| warning: false
describe(child22) |> html()

```

# Linear Regression Plans

## My First Research Question

Among children in the Midwest, Do specific social factors (age, sex, race, health status, and parental educational level) contribute to their mental health status score?

## My Quantitative Outcome

For this research question, we will use the *Strengths and Difficulties Questionnaire* (**SDQ**) score to measure the subjects' mental health status. The outcome is named `sdq` in the tibble. We are interested in using this outcome because it is an objective measure of the children mental health status. Hence, it will be a reliable tool in exploring potential associations with social factors, namely their age, sex, race, health status, and parental educational level.

```{r}

count(complete.cases(child22$sdq))

```

There are 1173 cases with complete `sdq` score values.

```{r}
#| warning: false

p1 <- ggplot(child22, aes(sample = sdq)) +
  geom_qq(col = "navyblue") + geom_qq_line(col = "pink") + 
  theme(aspect.ratio = 1) +
    labs(y = "(SDQ) total score", 
         x = "Standard Normal Distribution")

p2 <- ggplot(child22, aes(x = sdq)) +
  geom_histogram(aes(y = stat(density)), 
                 bins = 10, fill = "navyblue", col = "white") +
  stat_function(fun = dnorm, 
                args = list(mean = mean(child22$sdq), 
                            sd = sd(child22$sdq)),
                col = "pink", lwd = 1.5) +
  labs(y = "count", x = "(SDQ) total score")

p3 <- ggplot(child22, aes(x = sdq, y = "")) +
  geom_violin(fill = "navyblue") +
  geom_boxplot(width = 0.3, col = "white", notch = TRUE, 
               outlier.color = "navyblue") +
  labs(x = "(SDQ) total score", y = "")

p1 + (p2 / p3 + plot_layout(heights = c(4,1))) +
  plot_annotation(title = "SDQ Total Scores from NHIS Data",
       subtitle = "Higher SDQ score indicates more psychological difficulties",
       caption = "n = 1173")

```

The outcome is not normally distributed, rather, it is remarkably right skewed. A transformation should be considered.

```{r}
describe(child22$sdq)

```

As we can see, the outcome `sdq` is a quantitative variable with more than 10 ordinal values.

## My Planned Predictors (Linear Model)

The social background encompasses multiple variables including their `sex`, `age`, `race`, `health_status`, and parental educational level `adult_edu`.

The `age` variable is quantitative with more than 10 ordered observations:

```{r}

describe(child22$age)

```

`race` is a categorical variable with 5 levels. Each level contains over 30 observations:

```{r}

tabyl(child22$race)

```

We will demonstrate that the total number of candidate predictors we suggest is no more than: 4+(N1-100)/100. N1 is the total number of rows with complete outcome `sdq` data = 1173. 4+(1173-100)/100 = 14.73 \~ 15

The total number of candidate predictors is 5 (`sex`, `age`, `race`, `health_status`, and `adult_edu`) which is way below 15.

The first speculation we hold is that females may be associated with higher `sdq` scores. Our belief is based on the fact that females experience puberty earlier than their male counterpart, which is strongly associated with mental health outcomes. We believe that the child's health status and parental educational level may have a negative association with their `sdq` mental health score. We also speculate that race may contribute to their mental health score, where children from minority groups may have higher scores compared to other race categories.

# Logistic Regression Plans

## My Second Research Question

Among children in the Midwest, Do specific social factors (age, sex, race, health status, and parental educational level) contribute to the probability of witnessing or experiencing violence?

## My Binary Outcome

The outcome is the odds of children being victims or witnesses of violence. It is present in the tibble as `violence`. We are interested in using this measure to calculate the odds of children facing adverse events when selected social factors are taken into account. This can be a powerful tool in predicting and preventing child abuse. It can also be used in creating a "profile" of children most likely becoming victims of violence based on their social background.

The outcome variable:

```{r}

tabyl(child22$violence)

```

`violence` has two categories: yes and no. There are 22 missing values.

## My Planned Predictors (Logistic Model)

The social background encompasses multiple variables including the child's `sex`, `age`, `race`, `health_status`, and parental educational level `adult_edu`.

The `age` variable is quantitative with more than 10 ordered observations:

```{r}

describe(child22$age)

```

`race` is a 5 level categorical variable, with each level having over 30 observations:

```{r}

tabyl(child22$race)

```

We will demonstrate that the total number of candidate predictors we suggest is no more than: 4+(N2-100)/100. N2 is the number of the smaller group in the outcome `violence`. In this case N2 = 90. 4+(90-100)/100 = 3.9 \~ 4

The total number of candidate predictors is 5 (`sex`, `age`, `race`, `health_status`, and `adult_edu`) which is more than the suggested number. We will have to remove one predictor before proceeding to analysis.

The first speculation we hold is that younger children (one of the most vulnerable populations) have higher odds of being victims of or witnessing violence. We also believe that the child's health status and parental educational level may have a negative association with the odds of them being victims or witnesses of violence. Race could contribute to outcome, where children from minority groups may have higher odds of being victims of or witnessing violence compared to children from other race categories.

# Linear Regression Analyses

## Missingness

We will use `miss_var_summary` to assess the missingness

```{r}
miss_var_summary(child22) |> filter(n_miss > 0)
```

We've noticed that there are missing observations in our outcome variable `sdq` and the predictor variable `health_status`.

### Single Imputation Approach

For this analysis, we will proceed under the assumption that the observations are missing at random (MAR). Under this assumption, using a single imputation method to handle the missing values is suitable for our predictor `health_status`. We’ll use the `simputation` package to accomplish it. However, we will exclude all the missing observations in our outcome via complete cases.

```{r}
child22_sub <- child22 |>
  select(sdq, sex, race, adult_edu, age, health_status)|>
  filter(complete.cases(sdq))|>
  impute_cart(health_status ~ sex + race + adult_edu+ age+ sdq)
n_miss(child22_sub)
```

We used the `n_miss` function to ensure that we obtained zero missing observations.

## Outcome Transformation

We will use Box-Cox function to determine whether our outcome requires transformation to improve its skewness.

```{r}
mod_temp <- lm(sdq ~ age + sex + race + adult_edu + health_status, data = child22_sub)

car::boxCox(mod_temp)
```

With a suggested transformation power of around 0.4, it appears that a square root transformation might be the most appropriate approach in the current case.

To verify the given suggestion, we will generate appropriate visualization to assess the skewness

```{r}
child22_sub <- child22_sub |>
  mutate(sqrtsdq = sqrt(sdq))

p1 <- ggplot(data = child22_sub, aes(sample = sqrtsdq)) +
  geom_qq(col = "cornflowerblue") + geom_qq_line(col = "red") +
  theme(aspect.ratio = 1) +
  labs(x = "Expected N(0,1)", y = "sqrt(SDQ)")

p2 <- ggplot(data = child22_sub, aes(x = sqrtsdq)) +
  geom_histogram(bins = 12 , fill = "cornflowerblue", col = "white") + 
  labs(x = "sqrt(SDQ)", y = "counts")

p3 <- ggplot(data = child22_sub, aes(x = sqrtsdq, y = "")) +
  geom_violin() +
  geom_boxplot(fill = "cornflowerblue", width = 0.3,
               outlier.color = "cornflowerblue", outlier.size = 3) +
  stat_summary(fun = "mean", geom = "point",
               shape = 23, size = 3, fill = "white") +
  labs(y = "", x = "sqrt(SDQ)")

p1 + (p2 / p3 + plot_layout(heights = c(2,1)))+
  plot_annotation(title = "Evaluating the square root of SDQ score")
```

The graphs provided demonstrate that although some skewness is still visible in both the normal Q-Q plot and histogram, there has been an improvement. Furthermore, the violin plot demonstrates a reduction of the outliers.

## Scatterplot Matrix and Collinearity

We will evaluate collinearity between predictors via scatter plot matrix and variance inflation factors.

-   Scatter plot Matrix

```{r}
#| warning: false
#| message: false
ggpairs(child22_sub, columns = c("age", "sex", "race", 
                               "health_status", "adult_edu", "sqrtsdq"), 
        title = "Scatterplot Matrix")
```

At the bottom right corner, we observe the density function plot representing our outcome variable `sqrtsdq.` The correlation among the predictors is fairly modest, and the scatter plot matrix reveals no no major concerns regarding collinearity among predictors.

-   Checking Variance Inflation Factors

```{r}
mod_A <- lm(sqrtsdq ~ age + sex + race + health_status + adult_edu, data = child22_sub)

car::vif(mod_A)
```

The predictors' generalized variance inflation factors (GVIF) demonstrate a small level of collinearity. We therefore have no serious concerns with respect to collinearity.

## Model A

### Fitting Model A

Now we will build mod_A "main effect" which incorporates five predictors `age`, `sex`, `race`, `health_status`, `adult_edu` using `lm`.

```{r}
mod_A <- lm(sqrtsdq ~ age + sex + race + health_status + adult_edu, data = child22_sub)
```

Our next step will be to fit model A "main effect" with the `ols()` function from the `rms` package, which we will use later.

```{r}
dd <- datadist(child22_sub)
options(datadist = "dd")

mod_A_ols <- ols(sqrtsdq ~ age + sex + race + health_status + adult_edu,
                 data = child22_sub, x = TRUE, y = TRUE)
```

### Tidied Coefficient Estimates (Model A)

We will use the `tidy` function to obtain the estimates, standard error, lower and upper confidence interval and p-values.

```{r}
tidy(mod_A, conf.int = TRUE, conf.level = 0.95) |>
  select(term, estimate, se = std.error, 
         low95 = conf.low, high95 = conf.high, 
         p = p.value) |>
 gt() |> fmt_number(decimals = 3) |> tab_options(table.font.size = 20)
```

### Summarizing Fit (Model A)

In this section we will use `glance` function to obtain R-squared, Adj.r.squared, sigma, AIC and BIC, nobs, df, and df.residual.

```{r}
glance(mod_A) |>
  select(r2 = r.squared, adjr2 = adj.r.squared, sigma, 
         AIC, BIC, nobs, df, df.residual) |>
  kable(digits = c(3, 3, 2, 1, 1, 0, 0, 0))
```

The R-squared value indicates that the model accounts for 12.4% of the variation in `sqrtsdq.` The adjusted R-squared is an index and it is is 0.11, and the model is based on 1173 observations, and has 13 df.

### Regression Diagnostics (Model A)

Here, the code will yield four residual plots

```{r}
#| fig-height: 8

par(mfrow = c(2,2)); plot(mod_A); par(mfrow = c(2,2))
```

Given the outcome's discrete nature and the presence of four categorical predictors, we note certain patterns in our linearity assumption in the residual vs. fitted plot and the homoscedasticity assumption in the scale-location plots. However, the Q-Q plot of residuals reveals a few outliers at the lower end, albeit not influential as per the residuals vs. leverage plot (nothing passed the Cook's distance). In conclusion, while there are minor deviations, overall, our assumptions appear to be reasonably met.

## Non-Linearity

Presented below is the needed Spearman $\rho^2$ plot.

```{r}
plot(spearman2(sqrtsdq ~ age + sex + race + health_status + adult_edu,
                 data = child22_sub))
```

Based to the Spearman $\rho^2$ plot, the most attractive candidate predictors for non-linear terms are `health_status` and `adult_edu`, respectively. We will include an interaction between `health_status` (2 df) and `adult_edu` (5 df), which is expected to contribute 10 degrees of freedom to our initial model.

**Note**: this approach has received approval from Prof. Thomas Love on 2024-03-17.

## Model B

Our Model B will include one non-linear term the interaction between `health_status` and `adult_edu`, this should add about 10 degrees of freedom to our Model A.

### Fitting Model B

Now we will build augmented model B with interaction term which incorporates five predictors `age`, `sex`, `race`, `health_status`\*`adult_edu` using `lm`.

```{r}
mod_B <- lm(sqrtsdq ~ age + sex + race  + health_status * adult_edu, data = child22_sub)
```

Our next step will be to fit model B with the `ols()` function from the `rms` package.

```{r}
dd <- datadist(child22_sub)
options(datadist = "dd")

mod_B_ols <- ols(sqrtsdq ~ age + sex + race + health_status * adult_edu, data = child22_sub, x = TRUE, y = TRUE)
```

### Tidied Coefficient Estimates (Model B)

We will use the `tidy` function to obtain the estimates, standard error, lower and upper confidence interval and p-values.

```{r}
tidy(mod_B, conf.int = TRUE, conf.level = 0.95) |>
  select(term, estimate, se = std.error, 
         low95 = conf.low, high95 = conf.high, 
         p = p.value) |>
gt() |> fmt_number(decimals = 3) |> tab_options(table.font.size = 20)
```

### Effects Plot for Model B

Here, we will present a plot of the effects from `plot(summary(modelname))`for this augmented model, using `ols`

```{r}
plot(summary(mod_B_ols))
```

### Summarizing Fit (Model B)

In this section we will use `glance` function to obtain R-squared, Adj.r.squared, sigma, AIC and BIC, nobs, df, and df.residual.

```{r}
glance(mod_B) |>
  select(r2 = r.squared, adjr2 = adj.r.squared, sigma, 
         AIC, BIC, nobs, df, df.residual) |>
  kable(digits = c(3, 3, 2, 1, 1, 0, 0, 0))
```

In our Model B, we use `r glance(mod_B)$df` degrees of freedom, and obtain an $R^2$ value of `r round_half_up(glance(mod_B)$r.squared,3)`. The R-squared value indicates that the model accounts for 13 % of the variation in `sqrtsdq.` The adjusted R-squared is an index and it is is 0.11, and the model is based on 1173 observations, and has 23 df.

### Regression Diagnostics (Model B)

Here, the code will yield four residual plots

```{r}
#| fig-height: 8

par(mfrow = c(2,2)); plot(mod_B); par(mfrow = c(1,1))
```

Considering the discrete nature of the outcome and the presence of four categorical predictors, we observed certain patterns in the residual vs. fitted plot and the scale-location plots. However, these patterns do not substantially affect the linearity and homoscedasticity assumptions. Additionally, the Q-Q plot of residuals shows a few outliers at both ends. Among these outliers, observations 627 and 859 exhibit high leverage, but they are not influential according to the residuals vs. leverage plot (none exceed the Cook's distance threshold). In summary, while there are minor deviations, our assumptions seem to be reasonably met overall.

## Validating Models A and B

We will use the `validate()` function from the **rms** package to validate our `ols` fits that we previously created by re-sampling.

```{r}
set.seed(4321); (valA <- validate(mod_A_ols))
set.seed(4322); (valB <- validate(mod_B_ols))
```

After performing the validation, the output provides the R-squared value, MSE (mean squared error), intercept, and slope, along with their respective indices: "index.orig," "training," "test," and "optimism," which represents the difference between the training and test samples. Additionally, it includes the "index.corrected," calculated as "index.orig" minus "optimism."

### Validated $R^2$, and MSE as well as IC statistics {#sec-vallin}

| Model | Validated $R^2$ | Validated MSE | AIC | BIC | df |
|---:|:--:|:--:|:--:|:--:|:--:|
| A | `r round_half_up(valA[1,5],3)` | `r round_half_up(valA[2,5],4)` | `r round_half_up(AIC(mod_A),1)` | `r round_half_up(BIC(mod_A),1)` | `r glance(mod_A)$df` |
| B | `r round_half_up(valB[1,5],3)` | `r round_half_up(valB[2,5],4)` | `r round_half_up(AIC(mod_B),1)` | `r round_half_up(BIC(mod_B),1)` | `r glance(mod_B)$df` |

## Final Linear Regression Model

The table above provides information about the validated R-squared, MSE, AIC, and BIC. These values were obtained from a validation comparison between the "augmented model" B and the "main effects" model A, predicting the transformed outcome (sqrtsdq). Validated R-squared represents the percentage of variation in the outcome, while MSE stands for mean squared error, and AIC and BIC are Akaike and Bayesian Information Criteria, respectively. A more favorable fit is indicated by a higher validated R-squared and lower values of MSE, AIC, and BIC. In this case, **model A "main effects"** or the simple model shows a higher validated R-squared value and lower AIC and BIC, suggesting the most desirable fit, despite Model B having a lower validated MSE.Additionally, it's worth noting that the inclusion of interaction terms in the augmented model yields no apparent improvement.

### Winning Model's Parameter Estimates

Here, we will generate the content of mod_A_ols

```{r}
mod_A_ols
```

The validated $R^2$ value ( = `r round_half_up(valA[1,5],3)`) for our Model A

The output provides details about the formula used for the model, along with the number of observations. It includes the estimated residual standard deviation (sigma) and its corresponding degrees of freedom (df), as well as the model's likelihood ratio test and discrimination indexes. Additionally, it presents a statistical summary, including the minimum, first quartile (1Q), median, third quartile (3Q), and maximum values for "sqrtsdq." Finally, it lists the coefficient values, standard errors, t-test statistics, and p-values for all predictors.

### Effects Plot for Winning Model

Here, we will present a plot of the effects from `plot(summary(modelname))`for this simple main effect model, using `ols`

```{r}
plot(summary(mod_A_ols))
```

### Numerical Description of Effect Sizes

Here, we will obtain the effects summary of the `ols` model.

```{r}
summary(mod_A_ols) |> kable(digits = 3)
```

This effects summary of model A illustrates the impact on `sqrtsdq` when moving from the 25th to the 75th percentile of each variable. The estimates are accompanied by their respective standard errors and 95% confidence intervals, while maintaining the other variables at a constant level.

### Effect Size Description

**health_status** : If two children share the same age, sex, race, and parental education, our model predicts that a child reporting "Not very good" overall health status will have a square root of SDQ score 0.741 higher than a child reporting "Excellent" overall health. This prediction comes with a meaningful 95% confidence interval of (0.548, 0.880).

### Nomogram of Winning Model

Here, we will hypothetically generate predicted SDQ scores for two children, both female, one of White race and the other Hispanic. Both are 8 years old with reported "not very good" health statuses, and their parental education level is incomplete college education. Manually

-   Child one: age 8 = \~12.5 points, sex Female= 0 points, race White= \~ 47.5 points, health_status not very good = 100 points, adult_edu incomplete college= \~ 25, total points= \~ 185 and it is correspond to \~3.1 in the linear predictor scale.

-   Child two: age 8 = \~12.5 points, sex Female= 0 points, race Hispanic = \~ 21 points, health_status not very good = 100 points, adult_edu incomplete college= \~ 25, total points= \~ 185 and it is correspond to \~ 2.7 in the linear predictor scale.

These predicted values are square root.

```{r}
#| fig-height: 8
plot(nomogram(mod_A_ols, fun = exp))
```

### Prediction for a New Subject

We will generate predicted SDQ scores for two children, both female, one of White race and the other Hispanic. Both are 8 years old with reported "not very good" health statuses, and their parental education level is incomplete college education. We will use the code below and then squaring the predictions.

```{r}
new_subjects <- 
  data.frame(age = c(8,8), sex = c("Female", "Female"), race = c("White", "Hispanic"),
             health_status = c("Not very good", "Not very good"), adult_edu = c("incomplete_college", "incomplete_college"))

preds1 <- predict.lm(mod_A, newdata = new_subjects, 
                     interval = "prediction", level = 0.95)

(preds1)^2
```

| Predictor Values | Predicted SDQ | 95% Prediction Interval |
|:--:|:--:|:--:|
| age = 8, sex = Female, race= White, health_status = Not very good, adult_edu = incomplete_college | 9.78 | (1.59, 24.91) |
| age = 8, sex = Female, race= Hispanic, health_status = Not very good, adult_edu = incomplete_college | 8.66 | (1.16, 23.14) |

The code below will generate the predicted values in square root form, and they align with the values obtained from the nomogram plot.

```{r}
new_subjects <- 
  data.frame(age = c(8,8), sex = c("Female", "Female"), race = c("White", "Hispanic"),
             health_status = c("Not very good", "Not very good"), adult_edu = c("incomplete_college", "incomplete_college"))

preds2 <- predict.lm(mod_A, newdata = new_subjects, 
                     interval = "prediction", level = 0.95)

preds2
```

# Logistic Regression Analyses

We will start by creating a data subset including the predictors for the logistic regression analysis:

```{r}

child22_log <- child22|>
  select(id, sex, age, race, health_status, adult_edu, violence)

child22_log

```

Before proceeding any further, we will notice that our outcome `violence` is a factor. We will mutate it into a numeric variable with 0 and 1 levels.

```{r}

child22_log <- child22_log |> mutate(violence = as.numeric (violence))|> mutate(violence = 2 - violence)

```

## Predictor Selection

In the logistic analysis plan, we decided to reduce the number of predictors from 5 variables to 4 variables. All of the predictors included in the model are child social factors including their age, sex, race, and health status. Parental educational level `adult_edu` is the only variable associated with parents. This variable also has the highest number of levels (6 educational levels) and therefore will use more degrees of freedom compared to the rest of the predictors. Based on these facts, we decided to remove this variable from the logistic model.

The finalized logistic model data set will include be:

```{r}

child22_log <- child22_log|>
   select(-adult_edu)

child22_log

```

## Dealing with missingness

We will observe the number of subjects with missing observations and the proportion of missingness in our data set.

```{r}

miss_var_summary(child22_log)

```

There is a total of 23 subjects with missing observations and the overall proportion of missingness is 1.9%. In this case, imputing the missing observations is neither essential nor unnecessary, so we will proceed with the imputation process.

We will use the single imputation method using `simpute` function:

```{r}

set.seed(432)
child22_si <- child22_log |> data.frame() |>
  impute_rhd(violence ~ age + sex + race) |>
  impute_cart(health_status ~ age + sex + race) |>
  as_tibble()

n_miss(child22_si) 

```

## Model Y: Main effects model

### ModelY Results using `glm`

Now we will fit the main effects model using `glm` function.

```{r}

mody_g <- glm(violence ~ sex + age + race + health_status,
            data = child22_si, 
            family = binomial(link = logit))

```

Now we will produce a tidied table with the exponentiated estimates (odd ratios) with a 95% confidence interval.

```{r}

tidy(mody_g, exponentiate = TRUE, 
     conf.int = TRUE, conf.level = 0.95) |>
  select(term, estimate, std.error, 
         low95 = conf.low, high95 = conf.high, 
         p = p.value) |> 
  gt() |> 
  fmt_number(decimals = 3) |>
  tab_options(table.font.size = 20)

```

We will check for the presence of interaction between the predictors:

```{r}

rms::vif(mody_g)

```

As we can see, the inflation scores do not exceed the level of potential interaction. Therefore, we have no problems regarding collinearity between the predictors.

### ModelY Results using `lrm`

We will refit the same model using the `lrm` function.

```{r}
d <- datadist(child22_si)
options(datadist = "d")

mody_r <- lrm(violence ~ sex + age + race + health_status,
            data = child22_si, x = TRUE, y = TRUE)

```

Now we will produce an effects plot of the odds ratio scale for the model variables.

```{r}

plot(summary(mody_r))

```

We can also assess the relationship between each predictor and the outcome independently.

```{r}

ggplot(Predict(mody_r, fun = plogis))

```

### Key fit summary statistics

```{r}

mody_r

```

Nagelkerke value is 0.059, which indicates that our model does not present an improvement compared to a null model. The C statistic value is 0.674, which indicates that the predictions of our model are not very reliable.

### Confusion matrix

We will produce the confusion matrix using a cutting point of 0.08.

```{r}

mody_g_aug <- augment(mody_g, type.predict = "response")

cm <- confusionMatrix(
  data = factor(mody_g_aug$.fitted >= 0.08),
  reference = factor(mody_g_aug$violence == 1),
  positive = "TRUE")

cm

```

The sensitivity of our model is 60.4%, the specificity is 68.8%, and the positive predictive value is 13.8%.

## Non-linearity

Spearman $\rho^2$ plot

```{r}

plot(spearman2(violence ~ sex + age + race + health_status ,
            data = child22_si))

```

The Spearman $\rho^2$ plot is suggesting that `race` and `health_status` are the most suitable predictors for adding an interaction term. Since both variables are categorical, we will add an interaction term between `race` and `health_status`.

## Model Z: incorporating non-linear terms

Now we will fit another model with an interaction term between `race` and `health_status`.

```{r}

modz_r <- lrm(violence ~ sex + age + race + health_status + 
                 race %ia% health_status,
            data = child22_si, x = TRUE, y = TRUE)

```

Now we will confirm the number of additional degrees of freedom using anova:

```{r}

anova(modz_r)

```

The interaction resulted in 8 additional degrees of freedom.

### Modelz Results using `glm`

We can also use the glm function to produce tidied results of the interaction model.

```{r}

modz_g <- glm(violence ~ sex + age + race + health_status + 
                 race %ia% health_status,
                 data =child22_si, 
                 family =binomial(link =logit))

```

Tidied coefficients:

```{r}
#| message: false
#| warning: false

tidy(modz_g, exponentiate = TRUE, 
     conf.int = TRUE, conf.level = 0.95) |>
  select(term, estimate, std.error, 
         low90 = conf.low, high90 = conf.high) |> 
  gt() |> 
  fmt_number(decimals = 3) |> 
  tab_options(table.font.size = 14)

```

### Modelz Results using `lrm`

We will observe the plot of the effects using the `lrm` function:

```{r}

plot(summary(modz_r))

```

We can also assess the relationship between each predictor and the outcome independently.

```{r}

ggplot(Predict(modz_r, fun = plogis))

```

### Key fit summary statistics

```{r}

modz_r

```

Negelkerke value is 0.075, which indicates that our model does not present an improvement compared to a null model. The C statistic value is 0.682, which indicates that the predictions of our model are not very reliable.

### Confusion matrix

We will produce the confusion matrix using a cutting point of 0.08.

```{r}

modz_g_aug <- augment(modz_g, type.predict = "response")

cm <- confusionMatrix(
  data = factor(modz_g_aug$.fitted >= 0.08),
  reference = factor(modz_g_aug$violence == 1),
  positive = "TRUE")

cm

```

The sensitivity of our model is 60.4%, the specificity is 68.8%, and the positive predictive value is 13.8%. These values match the main effects model `mody` values.

## Validating the models

We will tidy the summaries of the main effects model `mody` and interaction model `modz` and compare them:

```{r}

temp1 <- bind_rows(glance(mody_g), glance(modz_g)) |>
  mutate(model = c("Y", "Z")) |>
  select(model, AIC, BIC) 

temp2 <- tibble(model = c("Y", "Z"),
  auc = c(mody_r$stats["C"], modz_r$stats["C"]),
  r2_nag = c(mody_r$stats["R2"], modz_r$stats["R2"]))

left_join(temp1, temp2, by = "model") |> 
  gt() |> fmt_number(columns = AIC:BIC, decimals = 1) |>
  fmt_number(columns = auc:r2_nag, decimals = 4) |> 
  tab_options(table.font.size = 20)

```

The interaction model `modz` has a slightly better performance compared to the main effects model `mody`.

Now we will validate the models to determine our final model:

```{r}

set.seed(432)
valY <- validate(mody_r, B = 40)
valZ <- validate(modz_r, B = 40)

val_1 <- bind_rows(valY[1,], valZ[1,]) |>
  mutate(model = c("Y", "Z"),
         AUC_nominal = 0.5 + (index.orig/2), 
         AUC_validated = 0.5 + (index.corrected/2)) |>
  select(model, AUC_nominal, AUC_validated)

val_2 <- bind_rows(valY[2,], valZ[2,]) |>
  mutate(model = c("Y", "Z"),
         R2_nominal = index.orig,
         R2_validated = index.corrected) |>
  select(model, R2_nominal, R2_validated)

val <- left_join(val_1, val_2, by = "model") 

val |> gt() |> fmt_number(decimals = 4) |> 
  tab_options(table.font.size = 20)

```

After validating the area under the curve value (AUC) and the R2 value, the main effects model `mody` displayed improved performance compared to the interaction model `modz`.

## Final Model

After validating the models, the main effects model `mody` yielded better results. Both the Nagelkerke's R squared and ROC values were improved compared to the interaction `modz` model. The main effects model `mody` will be the model of choice in this case.

The main effects model `mody` parameters and their coefficients with a 95% confidence interval is displayed in the following table:

```{r}


tidy(mody_g, exponentiate = TRUE, 
     conf.int = TRUE, conf.level = 0.95) |>
  select(term, estimate, std.error, 
         low95 = conf.low, high95 = conf.high, 
         p = p.value) |> 
  gt() |> 
  fmt_number(decimals = 3) |>
  tab_options(table.font.size = 20)

```

The social factor associated with the highest odds of violence is *African American* `race` (2.520) with a 95% CI (1.062, 6.082). The second highest social factor were *Other* `race` (2.116) with a 95% CI (0.857, 5.229) and `health status` *Not very good* (2.116) with a 95% CI (1.173, 3.717). The social factor associated with the lowest odds ratio of violence was the *Asian* `race` (0.425) with a 95% CI (0.064, 1.654 ). Among these factors, the only confidence intervals not containing 1 were **African American** `race` and **Not very good** `health status`, indicating that these factors produced meaningful differences in the odds ratio of violence.

To observe the effect sizes we will display the effect plot:

```{r}

plot(summary(mody_r))

```

According to this model, an 11 year old child has 1.5 the odds of witnessing/experiencing violence compared to a 4 year old child, when all other variables are held constant. Female children have about 1.4 times the odds of witnessing/experiencing violence compared to their male counterparts, also holding all other variables constant. When observing race, African American children have about 2.4 the odds witnessing/experiencing violence compared to White children, followed by Other races (2.0). Hispanic have about the same odds of witnessing/experiencing violence (about 1.0) while Asian children have lower odds of witnessing/experiencing violence (about 0.4) compared to White children. Compared to children with excellent health status, those with very good health status have about 1.7 the odds of witnessing/experiencing violence, while those with not very good health status have about 2.0 the odds of witnessing/experiencing violence. Again, these assumption are made when all other variables are held constant.

ROC Curve Plot

```{r}
#| message: false
#| warning: false

predict.prob1 <- predict(mody_g, type = "response")
roc1 <- pROC::roc(mody_g$data$violence, predict.prob1)

plot(roc1, main = "ROC Curve: Main effects model `mody`", lwd = 2, col = "navy")
legend('bottomright', legend = paste("AUC: ", 
                                     round_half_up(auc(roc1),4)))

```

The AUC values displayed here is the *nominal* AUC.

Validated Nagelkerke R-squared and the C statistic values

```{r}

set.seed(432)
valY <- validate(mody_r, B = 40)

val_1 <- bind_rows(valY[1,]) |>
  mutate(model = c("Y"),
         AUC_nominal = 0.5 + (index.orig/2), 
         AUC_validated = 0.5 + (index.corrected/2)) |>
  select(model, AUC_nominal, AUC_validated)

val_2 <- bind_rows(valY[2,]) |>
  mutate(model = c("Y"),
         R2_nominal = index.orig,
         R2_validated = index.corrected) |>
  select(model, R2_nominal, R2_validated)

val <- left_join(val_1, val_2, by = "model") 

val |> gt() |> fmt_number(decimals = 4) |> 
  tab_options(table.font.size = 20)


```

The validated area under the curve (AUC) value is 0.638. This means that our model's predictions are slightly better than a random guess. The validated Nagelkerke's R squared value is 0.022, which means that our model does not show an improvement compared to a null model.

Using the nomogram to make a prediction:

```{r}

plot(nomogram(mody_r, fun = plogis,
            fun.at = c(0.05, seq(0.1, 0.9, by = 0.1), 0.95),
            funlabel = "Pr(violence)"))

```

We can use the nomogram to predict the odds ration of children by imputing the values of their social factors. We will hypothesize two subjects. The first will be a female African American child who is 5 years old and does not have a very good health status. The second subject will be male Asian child who is 13 years old and has a very good health status. By using this nomogram the first subject is predicted to have approximately 2.1 the odds of witnessing/experiencing violence while the second subject will have about 0.05 the odds. The first subject has remarkably higher probability of witnessing/experiencing violence, while the second subject has a lower probability.

# Discussion

The first research question was: Among children in the Midwest, Do specific social factors (age, sex, race, health status, and parental educational level) contribute to their mental health status score? Based on the final linear regression model, a couple of the social factors contributed meaningfully to the outcome, specifically, **race** (Asian) and **health status** (not very good). Having an Asian race contributed positively to the mental health score, while having a not very good health status contributed negatively.

The second research question was: Among children in the Midwest, Do specific social factors (age, sex, race, health status, and parental educational level) contribute to the probability of witnessing or experiencing violence? Based on the final logistic regression model, a couple of the social factors contributed meaningfully to the outcome, specifically, **race** (African American) and **health status** (not very good). Children with these characteristics presented remarkably higher probabilities of witnessing or experiencing violence compared to children with different social characteristics.

Project A was a challenging, yet achievable project. One of the prominent issues we faced was that the outcome of the linear regression model was discrete. There were a few difficulties during the analysis, and we wished we were more proficient in other suitable methods such as the Poisson or negative binomial regression. Another challenge was choosing an appropriate transformation for the outcome. We used the Box-Cox to guide us, however that was not useful. So, we opted for a different transformation until reaching a satisfying result. We realized that the Box-Cox can be misleading. We also wished we had collapsed some of the categorical levels as they had used more degrees of freedom in the model. However, this decision may compromise our ability to investigate meaningful differences between the categorical levels. The overall process of the project was not difficult as there was a roadmap guiding us (the instructions). However, making decisions on the order of the logistic models (the main effects model and interaction model using glm and lrm function) was confusing at times. We decided to organize the models in a way that facilitated comprehension for the audience. We learned that it is imperative to keep our study goal in mind during the analysis process.

# Affirmation

I am certain that it is completely appropriate for these data to be shared with anyone, without any conditions. There are no concerns about privacy or security.

# References

-   Centers for Disease Control and Prevention. (2023, June 29). NHIS - 2022 NHIS. Centers for Disease Control and Prevention. <https://www.cdc.gov/nchs/nhis/2022nhis.htm>.

# Session Information

```{r}

xfun::session_info()

```
